{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDrTvtw8YkC5"
      },
      "outputs": [],
      "source": [
        "import os,cv2,keras\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZ2ffVDtlmMf"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u8JBfkTYu_N"
      },
      "outputs": [],
      "source": [
        "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8mV8QKrZgTg"
      },
      "source": [
        "# **calculate intersection over union**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSfeadg6Y2FX"
      },
      "outputs": [],
      "source": [
        "def get_iou(bb1, bb2):\n",
        "  assert bb1['x1'] < bb1['x2']\n",
        "  assert bb1['y1'] < bb1['y2']\n",
        "  assert bb2['x1'] < bb2['x2']\n",
        "  assert bb2['y1'] < bb2['y2']\n",
        "\n",
        "  x1 = max(bb1['x1'], bb2['x1'])\n",
        "  y1 = max(bb1['y1'], bb2['y1'])\n",
        "\n",
        "  x2 = min(bb1['x2'], bb2['x2'])\n",
        "  y2 = min(bb1['y2'], bb2['y2'])\n",
        "\n",
        "  if x2 < x1 or y2 < y1:\n",
        "    return 0.0\n",
        "  intersection_area = (x2 - x1) * (y2 - y1)\n",
        "  bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
        "  bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
        "  iou = intersection_area / float(bb1_area + bb2_area - intersection_area) # intersection over union\n",
        "  assert iou >= 0.0\n",
        "  assert iou <= 1.0\n",
        "  return iou"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OIZ0cAGZn0z"
      },
      "source": [
        "# **Load data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHsbCApIZZYu"
      },
      "outputs": [],
      "source": [
        "train_data = []\n",
        "train_labels = []\n",
        "couter = 0\n",
        "for i,image in enumerate(sorted(os.listdir('data/Images'))):\n",
        "  if \"airplane\" in image:\n",
        "    img = cv2.imread('data/Images/'+image)\n",
        "    train_data.append(img)\n",
        "for label in sorted(os.listdir('data/Airplanes_Annotations')):\n",
        "  if \"airplane\" in label:\n",
        "    df = pd.read_csv('data/Airplanes_Annotations/'+label)\n",
        "    t = []\n",
        "    for index,row in df.iterrows():\n",
        "      cords_str = row[0].split(\" \")\n",
        "      cord = {\"x1\":int(cords_str[0]),\"y1\":int(cords_str[1]),\"x2\":int(cords_str[2]),\"y2\":int(cords_str[3])}\n",
        "      t.append(cord)\n",
        "    train_labels.append(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVjLQKAzkO8Z"
      },
      "source": [
        "# **Selective Search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir6kuzg1lh8w"
      },
      "outputs": [],
      "source": [
        "def get_countours(train_data, train_labels):\n",
        "  training_images = []\n",
        "  training_labels = []\n",
        "\n",
        "  for i, img in enumerate(train_data):\n",
        "    try:\n",
        "      ss.setBaseImage(img)\n",
        "      ss.switchToSelectiveSearchFast()\n",
        "      ssresults = ss.process()\n",
        "      copy_img = img.copy()\n",
        "\n",
        "      num_positive_samples = 0\n",
        "      num_negative_samples = 0\n",
        "      for e, result in enumerate(ssresults):\n",
        "        if e < 4000:\n",
        "          x, y, w, h = result\n",
        "          for gtval in train_labels[i]:\n",
        "            iou = get_iou(gtval, {\"x1\": x, \"y1\": y, \"x2\": x + w, \"y2\": y + h})\n",
        "            if num_positive_samples < 30 and iou > 0.7:\n",
        "              cuted_image = copy_img[y:y + h, x:x + w]\n",
        "              resized = cv2.resize(cuted_image, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "              training_images.append(resized)\n",
        "              training_labels.append(1)\n",
        "              num_positive_samples += 1\n",
        "\n",
        "            if num_negative_samples < 30 and iou < 0.3:\n",
        "              cuted_image = copy_img[y:y + h, x:x + w]\n",
        "              resized = cv2.resize(cuted_image, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "              training_images.append(resized)\n",
        "              training_labels.append(0)\n",
        "              num_negative_samples += 1\n",
        "            if num_negative_samples==30 and num_positive_samples==30:\n",
        "              break\n",
        "        else:\n",
        "          break\n",
        "    except:\n",
        "      continue\n",
        "  return training_images, training_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKi2r8f0vJrP"
      },
      "outputs": [],
      "source": [
        "training_images,training_labels = get_countours(train_data,train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcRmtx4B6eQQ"
      },
      "outputs": [],
      "source": [
        "X = np.array(training_images)\n",
        "y = np.array(training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-ZcNSPxLZbh",
        "outputId": "4e15819c-5a7c-47ce-e756-fabe7f56a707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 24s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Dense\n",
        "from keras import Model\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications.vgg16 import VGG16\n",
        "vggmodel = VGG16(weights='imagenet', include_top=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bNDOjOiLeV2",
        "outputId": "66be0c0d-9e3a-47ad-e79b-d73b25f4c38c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 8194      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134268738 (512.19 MB)\n",
            "Trainable params: 126633474 (483.07 MB)\n",
            "Non-trainable params: 7635264 (29.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "for layers in vggmodel.layers[:15]:\n",
        "  layers.trainable = False\n",
        "inp = vggmodel.layers[-2].output\n",
        "predictions = Dense(2, activation='softmax')(inp)\n",
        "model_final = Model(inputs = vggmodel.input, outputs = predictions)\n",
        "opt = Adam(lr=0.0001)\n",
        "model_final.compile(loss = keras.losses.categorical_crossentropy, optimizer = opt, metrics=[\"accuracy\"])\n",
        "model_final.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYX8dYIrL8ha"
      },
      "outputs": [],
      "source": [
        "new_Y = []\n",
        "for val in y :\n",
        "  t = [0.,0.]\n",
        "  t[val] = 1.\n",
        "  new_Y.append(t)\n",
        "new_Y = np.array(new_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4jxSKoTN3T-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, new_Y, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KwheTTsOSmr"
      },
      "outputs": [],
      "source": [
        "trdata = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90,)\n",
        "traindata = trdata.flow(x=X_train, y=y_train,shuffle=True)\n",
        "tsdata = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
        "testdata = tsdata.flow(x=X_test, y=y_test,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnFWTptHRCO3",
        "outputId": "8c3d980f-a715-4b0d-9c10-7b3db4644f73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "<ipython-input-18-0de1866649d3>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  hist = model_final.fit_generator(generator= traindata, steps_per_epoch= 10, epochs= 100, validation_data= testdata, validation_steps=2, callbacks=[checkpoint,early])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 162.0459 - accuracy: 0.4688\n",
            "Epoch 1: val_loss improved from inf to 1.07591, saving model to ieeercnn_vgg16_1.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 30s 2s/step - loss: 162.0459 - accuracy: 0.4688 - val_loss: 1.0759 - val_accuracy: 0.5156\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 3.5568 - accuracy: 0.5375\n",
            "Epoch 2: val_loss improved from 1.07591 to 0.69521, saving model to ieeercnn_vgg16_1.h5\n",
            "10/10 [==============================] - 21s 2s/step - loss: 3.5568 - accuracy: 0.5375 - val_loss: 0.6952 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.1879 - accuracy: 0.5156\n",
            "Epoch 3: val_loss did not improve from 0.69521\n",
            "10/10 [==============================] - 5s 443ms/step - loss: 1.1879 - accuracy: 0.5156 - val_loss: 0.9214 - val_accuracy: 0.6094\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 3.3596 - accuracy: 0.5000\n",
            "Epoch 4: val_loss did not improve from 0.69521\n",
            "10/10 [==============================] - 10s 1s/step - loss: 3.3596 - accuracy: 0.5000 - val_loss: 0.7479 - val_accuracy: 0.4375\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7182 - accuracy: 0.4938\n",
            "Epoch 5: val_loss did not improve from 0.69521\n",
            "10/10 [==============================] - 4s 417ms/step - loss: 0.7182 - accuracy: 0.4938 - val_loss: 0.7148 - val_accuracy: 0.4844\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7117 - accuracy: 0.4969\n",
            "Epoch 6: val_loss improved from 0.69521 to 0.68104, saving model to ieeercnn_vgg16_1.h5\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.7117 - accuracy: 0.4969 - val_loss: 0.6810 - val_accuracy: 0.5781\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.5375\n",
            "Epoch 7: val_loss did not improve from 0.68104\n",
            "10/10 [==============================] - 5s 438ms/step - loss: 0.6912 - accuracy: 0.5375 - val_loss: 0.6998 - val_accuracy: 0.4844\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6958 - accuracy: 0.5469\n",
            "Epoch 8: val_loss did not improve from 0.68104\n",
            "10/10 [==============================] - 4s 425ms/step - loss: 0.6958 - accuracy: 0.5469 - val_loss: 0.6957 - val_accuracy: 0.4844\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6833 - accuracy: 0.5906\n",
            "Epoch 9: val_loss did not improve from 0.68104\n",
            "10/10 [==============================] - 4s 438ms/step - loss: 0.6833 - accuracy: 0.5906 - val_loss: 0.6923 - val_accuracy: 0.5312\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6980 - accuracy: 0.5281\n",
            "Epoch 10: val_loss did not improve from 0.68104\n",
            "10/10 [==============================] - 4s 423ms/step - loss: 0.6980 - accuracy: 0.5281 - val_loss: 0.8633 - val_accuracy: 0.4219\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7040 - accuracy: 0.5125\n",
            "Epoch 11: val_loss improved from 0.68104 to 0.64864, saving model to ieeercnn_vgg16_1.h5\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.7040 - accuracy: 0.5125 - val_loss: 0.6486 - val_accuracy: 0.6562\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6853 - accuracy: 0.5437\n",
            "Epoch 12: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 417ms/step - loss: 0.6853 - accuracy: 0.5437 - val_loss: 0.7776 - val_accuracy: 0.5469\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7506 - accuracy: 0.5031\n",
            "Epoch 13: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 418ms/step - loss: 0.7506 - accuracy: 0.5031 - val_loss: 0.7434 - val_accuracy: 0.6562\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8078 - accuracy: 0.4938\n",
            "Epoch 14: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 437ms/step - loss: 0.8078 - accuracy: 0.4938 - val_loss: 0.7027 - val_accuracy: 0.5469\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7190 - accuracy: 0.5594\n",
            "Epoch 15: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 414ms/step - loss: 0.7190 - accuracy: 0.5594 - val_loss: 0.6910 - val_accuracy: 0.5938\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6863 - accuracy: 0.5625\n",
            "Epoch 16: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 436ms/step - loss: 0.6863 - accuracy: 0.5625 - val_loss: 0.7584 - val_accuracy: 0.4688\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6825 - accuracy: 0.5312\n",
            "Epoch 17: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 422ms/step - loss: 0.6825 - accuracy: 0.5312 - val_loss: 0.6773 - val_accuracy: 0.6094\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7527 - accuracy: 0.4437\n",
            "Epoch 18: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 427ms/step - loss: 0.7527 - accuracy: 0.4437 - val_loss: 0.7495 - val_accuracy: 0.5312\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7023 - accuracy: 0.5875\n",
            "Epoch 19: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 421ms/step - loss: 0.7023 - accuracy: 0.5875 - val_loss: 0.6932 - val_accuracy: 0.4844\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7022 - accuracy: 0.4969\n",
            "Epoch 20: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 404ms/step - loss: 0.7022 - accuracy: 0.4969 - val_loss: 0.6887 - val_accuracy: 0.5469\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6622 - accuracy: 0.6438\n",
            "Epoch 21: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 414ms/step - loss: 0.6622 - accuracy: 0.6438 - val_loss: 0.7123 - val_accuracy: 0.4844\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6749 - accuracy: 0.6062\n",
            "Epoch 22: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 416ms/step - loss: 0.6749 - accuracy: 0.6062 - val_loss: 0.7147 - val_accuracy: 0.5469\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7187 - accuracy: 0.4875\n",
            "Epoch 23: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 416ms/step - loss: 0.7187 - accuracy: 0.4875 - val_loss: 0.7491 - val_accuracy: 0.4844\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7171 - accuracy: 0.4906\n",
            "Epoch 24: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 417ms/step - loss: 0.7171 - accuracy: 0.4906 - val_loss: 0.6734 - val_accuracy: 0.6250\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6786 - accuracy: 0.5969\n",
            "Epoch 25: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 430ms/step - loss: 0.6786 - accuracy: 0.5969 - val_loss: 0.7148 - val_accuracy: 0.5781\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7136 - accuracy: 0.5156\n",
            "Epoch 26: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 407ms/step - loss: 0.7136 - accuracy: 0.5156 - val_loss: 0.7447 - val_accuracy: 0.5156\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7372 - accuracy: 0.4469\n",
            "Epoch 27: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 425ms/step - loss: 0.7372 - accuracy: 0.4469 - val_loss: 0.7373 - val_accuracy: 0.4531\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6865 - accuracy: 0.5719\n",
            "Epoch 28: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 408ms/step - loss: 0.6865 - accuracy: 0.5719 - val_loss: 0.6759 - val_accuracy: 0.6094\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7016 - accuracy: 0.5031\n",
            "Epoch 29: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 416ms/step - loss: 0.7016 - accuracy: 0.5031 - val_loss: 0.6971 - val_accuracy: 0.5781\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7014 - accuracy: 0.5312\n",
            "Epoch 30: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 427ms/step - loss: 0.7014 - accuracy: 0.5312 - val_loss: 0.7813 - val_accuracy: 0.4531\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7037 - accuracy: 0.5219\n",
            "Epoch 31: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 408ms/step - loss: 0.7037 - accuracy: 0.5219 - val_loss: 0.6963 - val_accuracy: 0.4844\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6853 - accuracy: 0.5781\n",
            "Epoch 32: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 426ms/step - loss: 0.6853 - accuracy: 0.5781 - val_loss: 0.6848 - val_accuracy: 0.5781\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6800 - accuracy: 0.5938\n",
            "Epoch 33: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 413ms/step - loss: 0.6800 - accuracy: 0.5938 - val_loss: 0.6899 - val_accuracy: 0.5469\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6793 - accuracy: 0.5813\n",
            "Epoch 34: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 416ms/step - loss: 0.6793 - accuracy: 0.5813 - val_loss: 0.7400 - val_accuracy: 0.5625\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7328 - accuracy: 0.5375\n",
            "Epoch 35: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 438ms/step - loss: 0.7328 - accuracy: 0.5375 - val_loss: 0.7007 - val_accuracy: 0.4219\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7310 - accuracy: 0.5281\n",
            "Epoch 36: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 414ms/step - loss: 0.7310 - accuracy: 0.5281 - val_loss: 0.6881 - val_accuracy: 0.5625\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.5813\n",
            "Epoch 37: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 428ms/step - loss: 0.6906 - accuracy: 0.5813 - val_loss: 0.6809 - val_accuracy: 0.5781\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7469 - accuracy: 0.4875\n",
            "Epoch 38: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 411ms/step - loss: 0.7469 - accuracy: 0.4875 - val_loss: 0.6993 - val_accuracy: 0.4844\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.5500\n",
            "Epoch 39: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 428ms/step - loss: 0.6920 - accuracy: 0.5500 - val_loss: 0.6765 - val_accuracy: 0.6094\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6994 - accuracy: 0.5219\n",
            "Epoch 40: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 410ms/step - loss: 0.6994 - accuracy: 0.5219 - val_loss: 0.6992 - val_accuracy: 0.5625\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7521 - accuracy: 0.4875\n",
            "Epoch 41: val_loss did not improve from 0.64864\n",
            "10/10 [==============================] - 4s 408ms/step - loss: 0.7521 - accuracy: 0.4875 - val_loss: 0.7071 - val_accuracy: 0.5938\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7073 - accuracy: 0.5000\n",
            "Epoch 42: val_loss improved from 0.64864 to 0.63707, saving model to ieeercnn_vgg16_1.h5\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.7073 - accuracy: 0.5000 - val_loss: 0.6371 - val_accuracy: 0.6719\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7424 - accuracy: 0.4906\n",
            "Epoch 43: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 404ms/step - loss: 0.7424 - accuracy: 0.4906 - val_loss: 0.7015 - val_accuracy: 0.3906\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6773 - accuracy: 0.6094\n",
            "Epoch 44: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 427ms/step - loss: 0.6773 - accuracy: 0.6094 - val_loss: 0.6922 - val_accuracy: 0.5469\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7056 - accuracy: 0.5063\n",
            "Epoch 45: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 398ms/step - loss: 0.7056 - accuracy: 0.5063 - val_loss: 0.7608 - val_accuracy: 0.5156\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6803 - accuracy: 0.6031\n",
            "Epoch 46: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 418ms/step - loss: 0.6803 - accuracy: 0.6031 - val_loss: 0.7204 - val_accuracy: 0.5156\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7065 - accuracy: 0.4938\n",
            "Epoch 47: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 407ms/step - loss: 0.7065 - accuracy: 0.4938 - val_loss: 0.6890 - val_accuracy: 0.5469\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7089 - accuracy: 0.5406\n",
            "Epoch 48: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 418ms/step - loss: 0.7089 - accuracy: 0.5406 - val_loss: 0.6984 - val_accuracy: 0.4531\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6962 - accuracy: 0.5625\n",
            "Epoch 49: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 418ms/step - loss: 0.6962 - accuracy: 0.5625 - val_loss: 0.6790 - val_accuracy: 0.6094\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7087 - accuracy: 0.5031\n",
            "Epoch 50: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 416ms/step - loss: 0.7087 - accuracy: 0.5031 - val_loss: 0.6938 - val_accuracy: 0.5938\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.5375\n",
            "Epoch 51: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 417ms/step - loss: 0.6854 - accuracy: 0.5375 - val_loss: 0.6927 - val_accuracy: 0.6250\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6778 - accuracy: 0.6313\n",
            "Epoch 52: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 408ms/step - loss: 0.6778 - accuracy: 0.6313 - val_loss: 0.6899 - val_accuracy: 0.5625\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6800 - accuracy: 0.6031\n",
            "Epoch 53: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 402ms/step - loss: 0.6800 - accuracy: 0.6031 - val_loss: 0.6709 - val_accuracy: 0.6094\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6841 - accuracy: 0.5781\n",
            "Epoch 54: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 418ms/step - loss: 0.6841 - accuracy: 0.5781 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7149 - accuracy: 0.4844\n",
            "Epoch 55: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 419ms/step - loss: 0.7149 - accuracy: 0.4844 - val_loss: 0.6965 - val_accuracy: 0.5000\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6694 - accuracy: 0.6250\n",
            "Epoch 56: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 424ms/step - loss: 0.6694 - accuracy: 0.6250 - val_loss: 0.8515 - val_accuracy: 0.5312\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7182 - accuracy: 0.5312\n",
            "Epoch 57: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 421ms/step - loss: 0.7182 - accuracy: 0.5312 - val_loss: 0.7144 - val_accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6821 - accuracy: 0.5875\n",
            "Epoch 58: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 418ms/step - loss: 0.6821 - accuracy: 0.5875 - val_loss: 0.7212 - val_accuracy: 0.4375\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6861 - accuracy: 0.5969\n",
            "Epoch 59: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 418ms/step - loss: 0.6861 - accuracy: 0.5969 - val_loss: 0.7028 - val_accuracy: 0.5156\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6855 - accuracy: 0.5344\n",
            "Epoch 60: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 417ms/step - loss: 0.6855 - accuracy: 0.5344 - val_loss: 0.7419 - val_accuracy: 0.5938\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7582 - accuracy: 0.4844\n",
            "Epoch 61: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 406ms/step - loss: 0.7582 - accuracy: 0.4844 - val_loss: 0.6941 - val_accuracy: 0.5156\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7153 - accuracy: 0.5094\n",
            "Epoch 62: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 422ms/step - loss: 0.7153 - accuracy: 0.5094 - val_loss: 0.7083 - val_accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7078 - accuracy: 0.5688\n",
            "Epoch 63: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 413ms/step - loss: 0.7078 - accuracy: 0.5688 - val_loss: 0.7043 - val_accuracy: 0.4531\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6754 - accuracy: 0.6031\n",
            "Epoch 64: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 400ms/step - loss: 0.6754 - accuracy: 0.6031 - val_loss: 0.7600 - val_accuracy: 0.4531\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6998 - accuracy: 0.5375\n",
            "Epoch 65: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 432ms/step - loss: 0.6998 - accuracy: 0.5375 - val_loss: 0.7154 - val_accuracy: 0.4375\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6887 - accuracy: 0.5500\n",
            "Epoch 66: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 411ms/step - loss: 0.6887 - accuracy: 0.5500 - val_loss: 0.7584 - val_accuracy: 0.4531\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6810 - accuracy: 0.5818\n",
            "Epoch 67: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 413ms/step - loss: 0.6810 - accuracy: 0.5818 - val_loss: 0.6887 - val_accuracy: 0.5469\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.5750\n",
            "Epoch 68: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 403ms/step - loss: 0.6857 - accuracy: 0.5750 - val_loss: 0.6862 - val_accuracy: 0.5625\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6962 - accuracy: 0.4750\n",
            "Epoch 69: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 415ms/step - loss: 0.6962 - accuracy: 0.4750 - val_loss: 0.6959 - val_accuracy: 0.4844\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7022 - accuracy: 0.5156\n",
            "Epoch 70: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 423ms/step - loss: 0.7022 - accuracy: 0.5156 - val_loss: 0.7295 - val_accuracy: 0.3750\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6981 - accuracy: 0.5469\n",
            "Epoch 71: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 415ms/step - loss: 0.6981 - accuracy: 0.5469 - val_loss: 0.6816 - val_accuracy: 0.5938\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6830 - accuracy: 0.5969\n",
            "Epoch 72: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 402ms/step - loss: 0.6830 - accuracy: 0.5969 - val_loss: 0.7116 - val_accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5312\n",
            "Epoch 73: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 435ms/step - loss: 0.6927 - accuracy: 0.5312 - val_loss: 0.7417 - val_accuracy: 0.5312\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.5406\n",
            "Epoch 74: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 412ms/step - loss: 0.6872 - accuracy: 0.5406 - val_loss: 0.6945 - val_accuracy: 0.5781\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6855 - accuracy: 0.5688\n",
            "Epoch 75: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 438ms/step - loss: 0.6855 - accuracy: 0.5688 - val_loss: 0.6959 - val_accuracy: 0.4375\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7076 - accuracy: 0.5094\n",
            "Epoch 76: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 417ms/step - loss: 0.7076 - accuracy: 0.5094 - val_loss: 0.6690 - val_accuracy: 0.6094\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.5125\n",
            "Epoch 77: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 404ms/step - loss: 0.6941 - accuracy: 0.5125 - val_loss: 0.7392 - val_accuracy: 0.4531\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6899 - accuracy: 0.5469\n",
            "Epoch 78: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 438ms/step - loss: 0.6899 - accuracy: 0.5469 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6995 - accuracy: 0.4844\n",
            "Epoch 79: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 406ms/step - loss: 0.6995 - accuracy: 0.4844 - val_loss: 0.7015 - val_accuracy: 0.3906\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7043 - accuracy: 0.5094\n",
            "Epoch 80: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 405ms/step - loss: 0.7043 - accuracy: 0.5094 - val_loss: 0.7228 - val_accuracy: 0.5156\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6989 - accuracy: 0.4625\n",
            "Epoch 81: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 406ms/step - loss: 0.6989 - accuracy: 0.4625 - val_loss: 0.6930 - val_accuracy: 0.5156\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5344\n",
            "Epoch 82: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 408ms/step - loss: 0.6927 - accuracy: 0.5344 - val_loss: 0.7006 - val_accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.5156\n",
            "Epoch 83: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 422ms/step - loss: 0.6922 - accuracy: 0.5156 - val_loss: 0.6889 - val_accuracy: 0.5625\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7166 - accuracy: 0.5063\n",
            "Epoch 84: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 395ms/step - loss: 0.7166 - accuracy: 0.5063 - val_loss: 0.7347 - val_accuracy: 0.3750\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7197 - accuracy: 0.5531\n",
            "Epoch 85: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 411ms/step - loss: 0.7197 - accuracy: 0.5531 - val_loss: 0.7295 - val_accuracy: 0.4531\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7082 - accuracy: 0.5531\n",
            "Epoch 86: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 431ms/step - loss: 0.7082 - accuracy: 0.5531 - val_loss: 0.9349 - val_accuracy: 0.4844\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7743 - accuracy: 0.4812\n",
            "Epoch 87: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 421ms/step - loss: 0.7743 - accuracy: 0.4812 - val_loss: 0.6892 - val_accuracy: 0.5469\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6878 - accuracy: 0.5938\n",
            "Epoch 88: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 419ms/step - loss: 0.6878 - accuracy: 0.5938 - val_loss: 0.6989 - val_accuracy: 0.5312\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.5469\n",
            "Epoch 89: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 421ms/step - loss: 0.6923 - accuracy: 0.5469 - val_loss: 0.6478 - val_accuracy: 0.7031\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6900 - accuracy: 0.5594\n",
            "Epoch 90: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 412ms/step - loss: 0.6900 - accuracy: 0.5594 - val_loss: 0.6753 - val_accuracy: 0.6250\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5250\n",
            "Epoch 91: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 427ms/step - loss: 0.6931 - accuracy: 0.5250 - val_loss: 0.7524 - val_accuracy: 0.4219\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6964 - accuracy: 0.5469\n",
            "Epoch 92: val_loss did not improve from 0.63707\n",
            "10/10 [==============================] - 4s 420ms/step - loss: 0.6964 - accuracy: 0.5469 - val_loss: 0.7029 - val_accuracy: 0.4219\n",
            "Epoch 92: early stopping\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"ieeercnn_vgg16_1.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=50, verbose=1, mode='auto')\n",
        "hist = model_final.fit_generator(generator= traindata, steps_per_epoch= 10, epochs= 500, validation_data= testdata, validation_steps=2, callbacks=[checkpoint,early])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XneUlReYv-z"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "best_model = load_model(\"ieeercnn_vgg16_1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-TvBNx7UKEX",
        "outputId": "e9038ea1-d2f2-49eb-8284-cf307584eb17"
      },
      "outputs": [],
      "source": [
        "img = X_train[3]\n",
        "ss.setBaseImage(img)\n",
        "ss.switchToSelectiveSearchFast()\n",
        "ssresults = ss.process()\n",
        "imout = img.copy()\n",
        "for e,result in enumerate(ssresults):\n",
        "    if e < 2000:\n",
        "        x,y,w,h = result\n",
        "        timage = imout[y:y+h,x:x+w]\n",
        "        resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
        "        img = np.expand_dims(resized, axis=0)\n",
        "        out= model_final.predict(img,verbose=0)\n",
        "        print(out)\n",
        "        if out[0][1] > 0.8:\n",
        "            cv2.rectangle(imout, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n",
        "            plt.figure()\n",
        "            plt.imshow(imout)\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1lsJiQJH_01"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
